{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c13328a-24d7-4984-b7f1-561471e8223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch, torchvision\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1 torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6c8f3e-b0d2-4126-9f74-c5afa974dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec96b9f5-9325-4413-8c4d-c1d309a6c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/200\n",
      "Training Loss: 0.516214\n",
      "Validation Loss: 1.240808\n",
      "\n",
      "Epoch: 20/200\n",
      "Training Loss: 0.223531\n",
      "Validation Loss: 1.464521\n",
      "\n",
      "Epoch: 30/200\n",
      "Training Loss: 0.154579\n",
      "Validation Loss: 1.536503\n",
      "\n",
      "Epoch: 40/200\n",
      "Training Loss: 0.110389\n",
      "Validation Loss: 1.524194\n",
      "\n",
      "Epoch: 50/200\n",
      "Training Loss: 0.090701\n",
      "Validation Loss: 1.506324\n",
      "\n",
      "Epoch: 60/200\n",
      "Training Loss: 0.094286\n",
      "Validation Loss: 1.387596\n",
      "\n",
      "Epoch: 70/200\n",
      "Training Loss: 0.077886\n",
      "Validation Loss: 1.541332\n",
      "\n",
      "Epoch: 80/200\n",
      "Training Loss: 0.103308\n",
      "Validation Loss: 1.451421\n",
      "\n",
      "Epoch: 90/200\n",
      "Training Loss: 0.056926\n",
      "Validation Loss: 1.524563\n",
      "\n",
      "Epoch: 100/200\n",
      "Training Loss: 0.061286\n",
      "Validation Loss: 1.506006\n",
      "\n",
      "Epoch: 110/200\n",
      "Training Loss: 0.052225\n",
      "Validation Loss: 1.461072\n",
      "\n",
      "Epoch: 120/200\n",
      "Training Loss: 0.050127\n",
      "Validation Loss: 1.380082\n",
      "\n",
      "Epoch: 130/200\n",
      "Training Loss: 0.042810\n",
      "Validation Loss: 1.415316\n",
      "\n",
      "Epoch: 140/200\n",
      "Training Loss: 0.055436\n",
      "Validation Loss: 1.370927\n",
      "\n",
      "Epoch: 150/200\n",
      "Training Loss: 0.043712\n",
      "Validation Loss: 1.424672\n",
      "\n",
      "Epoch: 160/200\n",
      "Training Loss: 0.043292\n",
      "Validation Loss: 1.376588\n",
      "\n",
      "Epoch: 170/200\n",
      "Training Loss: 0.052987\n",
      "Validation Loss: 1.363695\n",
      "\n",
      "Epoch: 180/200\n",
      "Training Loss: 0.036472\n",
      "Validation Loss: 1.381855\n",
      "\n",
      "Epoch: 190/200\n",
      "Training Loss: 0.040058\n",
      "Validation Loss: 1.390423\n",
      "\n",
      "Epoch: 200/200\n",
      "Training Loss: 0.037120\n",
      "Validation Loss: 1.352766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class StockPredictionModel(nn.Module):\n",
    "    def __init__(self, input_features=70, dropout_rate=0.1):\n",
    "        super(StockPredictionModel, self).__init__()\n",
    "        \n",
    "        # 1D CNN layers with specified number of kernels (32, 64, 128)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_features, out_channels=32, kernel_size=5, padding='same')\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding='same')\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding='same')\n",
    "        \n",
    "        # Activation function\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128, 220)\n",
    "        self.fc2 = nn.Linear(220, 1)  # Final output for prediction\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input for 1D convolution if needed\n",
    "        # Input shape: (batch_size, sequence_length, input_features)\n",
    "        # Required shape: (batch_size, input_features, sequence_length)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Apply CNN layers\n",
    "        x = self.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=200, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "            print(f'Training Loss: {train_loss/len(train_loader):.6f}')\n",
    "            print(f'Validation Loss: {val_loss/len(val_loader):.6f}\\n')\n",
    "\n",
    "# Example usage\n",
    "def prepare_data(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Prepare data for the model\n",
    "    data: numpy array of shape (n_samples, n_features)\n",
    "    sequence_length: number of time steps to look back\n",
    "    Returns:\n",
    "        X: tensor of shape (n_samples, sequence_length, n_features)\n",
    "        y: tensor of shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length), :])  # Keep all features\n",
    "        y.append(data[i + sequence_length, 0])  # Assuming first feature is the target\n",
    "    return torch.FloatTensor(np.array(X)), torch.FloatTensor(np.array(y)).reshape(-1, 1)\n",
    "\n",
    "# Example of how to use the model\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model with the specified parameters\n",
    "    model = StockPredictionModel(input_features=70, dropout_rate=0.1)\n",
    "    \n",
    "    # Create dummy data for demonstration\n",
    "    batch_size = 64\n",
    "    sequence_length = 10\n",
    "    n_features = 70\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Generate dummy data\n",
    "    dummy_data = np.random.randn(n_samples, n_features)\n",
    "    X, y = prepare_data(dummy_data, sequence_length)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775103f-1fb0-4f4c-901e-485a4f66997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-cpsc330]",
   "language": "python",
   "name": "conda-env-anaconda3-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
